{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project data gathered from four datasets with different sources for analysing US immigration data in a simple star schema. The main aim is to provide analytics to answer business questions which can be analyze and provide insight into the pattern of immigration. The analysis questions can be answered based on the data model using simple joins.\n",
    "Spark was used for the ETL pipeline and The final data is stored in parquet files for analysis.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10444/3846855442.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# all imports and installs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# all imports and installs \n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "plan to do in the project is create a simple star schema data warehouse with 1 fact table and 5 dimensional tables saved in parquet format, for analytical purposes that allows better undersanding of the immigration trends to the US using 4 datasets I94 Immigration Data, World Temperature Data, U.S. City Demographic Data, and Airport Code Table, and manipulate them using Pyspark.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The data sets:\n",
    "[I94 Immigration Data] This data comes from the US National Tourism and Trade Office. the data in csv format.\n",
    "includes data about the immigrants also the year, month, arrival and depture dates of immigrations and more.\n",
    "[World Temperature Data]: dataset came from Kaggle. includes the date and average temperature for cities\n",
    "[U.S. City Demographic Data]: This data comes from OpenSoft. includes demographics data for each city in U.S.\n",
    "[Airport Code Table]: This data comes from datahub.io. includes a simple table of airport codes and corresponding cities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "2      WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
       "3      WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
       "4      WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the immigration data sample\n",
    "df_immigration=spark.read.parquet(\"sas_data\")\n",
    "\n",
    "#df_immigration=pd.read_csv(\"immigration_data_sample.csv\")\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the us-cities-demographics data\n",
    "df_cities=spark.read.csv(\"us-cities-demographics.csv\",header=True,sep=';')\n",
    "df_cities.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the airport-codes_csv data\n",
    "df_airport=spark.read.csv(\"airport-codes_csv.csv\",header=True)\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Tempratures data\n",
    "df_temperature = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True)\n",
    "df_temperature.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visapost</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SYD</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>QF</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SYD</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>VA</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SYD</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SYD</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SYD</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa visapost  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0    40.0      1.0      SYD   1976.0  10292016      F   \n",
       "1      NV  20591.0    32.0      1.0      SYD   1984.0  10292016      F   \n",
       "2      WA  20582.0    29.0      1.0      SYD   1987.0  10292016      M   \n",
       "3      WA  20588.0    29.0      1.0      SYD   1987.0  10292016      F   \n",
       "4      WA  20588.0    28.0      1.0      SYD   1988.0  10292016      M   \n",
       "\n",
       "  airline  fltno visatype  \n",
       "0      QF  00011       B1  \n",
       "1      VA  00007       B1  \n",
       "2      DL  00040       B1  \n",
       "3      DL  00040       B1  \n",
       "4      DL  00040       B1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing cleaning tasks\n",
    "\n",
    "# Drop unnecessary columns in immigration data sample (df_immigration)\n",
    "\n",
    "df_immigration = df_immigration.drop('count','occup','entdepa','entdepd','entdepu','matflag','insnum','admnum','dtadfile')\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visapost</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0  299.0  2016.0     4.0   103.0   103.0     NYC  20545.0      1.0      NY   \n",
       "1  305.0  2016.0     4.0   103.0   103.0     NYC  20545.0      1.0      NY   \n",
       "2  496.0  2016.0     4.0   103.0   103.0     CHI  20545.0      1.0      IL   \n",
       "3  558.0  2016.0     4.0   103.0   103.0     SFR  20545.0      1.0      CA   \n",
       "4  596.0  2016.0     4.0   103.0   103.0     NAS  20545.0      1.0      FL   \n",
       "\n",
       "   depdate  i94bir  i94visa visapost  biryear   dtaddto gender airline  fltno  \\\n",
       "0  20550.0    54.0      2.0     None   1962.0  06292016   None      OS  00087   \n",
       "1  20555.0    63.0      2.0     None   1953.0  06292016   None      OS  00087   \n",
       "2  20548.0    64.0      1.0     None   1952.0  06292016   None      OS  00065   \n",
       "3  20547.0    42.0      1.0     None   1974.0  06292016      M      LH  00454   \n",
       "4  20547.0    24.0      2.0     None   1992.0  06292016      M      UP  00221   \n",
       "\n",
       "  visatype  \n",
       "0       WT  \n",
       "1       WT  \n",
       "2       WB  \n",
       "3       WB  \n",
       "4       WT  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping any rows of immigration DataFrame with duplicate CICID.\n",
    "df_immigration = df_immigration.dropDuplicates([\"cicid\"])\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visapost</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0  299.0  2016.0     4.0   103.0   103.0     NYC  20545.0      1.0      NY   \n",
       "1  305.0  2016.0     4.0   103.0   103.0     NYC  20545.0      1.0      NY   \n",
       "2  496.0  2016.0     4.0   103.0   103.0     CHI  20545.0      1.0      IL   \n",
       "3  558.0  2016.0     4.0   103.0   103.0     SFR  20545.0      1.0      CA   \n",
       "4  596.0  2016.0     4.0   103.0   103.0     NAS  20545.0      1.0      FL   \n",
       "\n",
       "   depdate  i94bir  i94visa visapost  biryear   dtaddto gender airline  fltno  \\\n",
       "0  20550.0    54.0      2.0     None   1962.0  06292016   None      OS  00087   \n",
       "1  20555.0    63.0      2.0     None   1953.0  06292016   None      OS  00087   \n",
       "2  20548.0    64.0      1.0     None   1952.0  06292016   None      OS  00065   \n",
       "3  20547.0    42.0      1.0     None   1974.0  06292016      M      LH  00454   \n",
       "4  20547.0    24.0      2.0     None   1992.0  06292016      M      UP  00221   \n",
       "\n",
       "  visatype  \n",
       "0       WT  \n",
       "1       WT  \n",
       "2       WB  \n",
       "3       WB  \n",
       "4       WT  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with 100% missing values.\n",
    "\n",
    "df_immigration = df_immigration.dropna(how='all')\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with missing values in i94port, i94addr\n",
    "df_immigration = df_immigration.dropna(how=\"any\", subset=[\"i94port\", \"i94addr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>CONNECTICUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DE</td>\n",
       "      <td>DELAWARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DC</td>\n",
       "      <td>DIST. OF COLUMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GU</td>\n",
       "      <td>GUAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HI</td>\n",
       "      <td>HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID</td>\n",
       "      <td>IDAHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IL</td>\n",
       "      <td>ILLINOIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IN</td>\n",
       "      <td>INDIANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IA</td>\n",
       "      <td>IOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KS</td>\n",
       "      <td>KANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KY</td>\n",
       "      <td>KENTUCKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LA</td>\n",
       "      <td>LOUISIANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ME</td>\n",
       "      <td>MAINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MD</td>\n",
       "      <td>MARYLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MA</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MI</td>\n",
       "      <td>MICHIGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MN</td>\n",
       "      <td>MINNESOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MS</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MO</td>\n",
       "      <td>MISSOURI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MT</td>\n",
       "      <td>MONTANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NC</td>\n",
       "      <td>N. CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ND</td>\n",
       "      <td>N. DAKOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NE</td>\n",
       "      <td>NEBRASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NV</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NH</td>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NJ</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NM</td>\n",
       "      <td>NEW MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OH</td>\n",
       "      <td>OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>OK</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OR</td>\n",
       "      <td>OREGON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PA</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PR</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>RI</td>\n",
       "      <td>RHODE ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SC</td>\n",
       "      <td>S. CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SD</td>\n",
       "      <td>S. DAKOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TN</td>\n",
       "      <td>TENNESSEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TX</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>UT</td>\n",
       "      <td>UTAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>VT</td>\n",
       "      <td>VERMONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>VI</td>\n",
       "      <td>VIRGIN ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VA</td>\n",
       "      <td>VIRGINIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>WV</td>\n",
       "      <td>W. VIRGINIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>WA</td>\n",
       "      <td>WASHINGTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>WI</td>\n",
       "      <td>WISCONSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WY</td>\n",
       "      <td>WYOMING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>99</td>\n",
       "      <td>All Other Codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code              state\n",
       "0          AL            ALABAMA\n",
       "1          AK             ALASKA\n",
       "2          AZ            ARIZONA\n",
       "3          AR           ARKANSAS\n",
       "4          CA         CALIFORNIA\n",
       "5          CO           COLORADO\n",
       "6          CT        CONNECTICUT\n",
       "7          DE           DELAWARE\n",
       "8          DC  DIST. OF COLUMBIA\n",
       "9          FL            FLORIDA\n",
       "10         GA            GEORGIA\n",
       "11         GU               GUAM\n",
       "12         HI             HAWAII\n",
       "13         ID              IDAHO\n",
       "14         IL           ILLINOIS\n",
       "15         IN            INDIANA\n",
       "16         IA               IOWA\n",
       "17         KS             KANSAS\n",
       "18         KY           KENTUCKY\n",
       "19         LA          LOUISIANA\n",
       "20         ME              MAINE\n",
       "21         MD           MARYLAND\n",
       "22         MA      MASSACHUSETTS\n",
       "23         MI           MICHIGAN\n",
       "24         MN          MINNESOTA\n",
       "25         MS        MISSISSIPPI\n",
       "26         MO           MISSOURI\n",
       "27         MT            MONTANA\n",
       "28         NC        N. CAROLINA\n",
       "29         ND          N. DAKOTA\n",
       "30         NE           NEBRASKA\n",
       "31         NV             NEVADA\n",
       "32         NH      NEW HAMPSHIRE\n",
       "33         NJ         NEW JERSEY\n",
       "34         NM         NEW MEXICO\n",
       "35         NY           NEW YORK\n",
       "36         OH               OHIO\n",
       "37         OK           OKLAHOMA\n",
       "38         OR             OREGON\n",
       "39         PA       PENNSYLVANIA\n",
       "40         PR        PUERTO RICO\n",
       "41         RI       RHODE ISLAND\n",
       "42         SC        S. CAROLINA\n",
       "43         SD          S. DAKOTA\n",
       "44         TN          TENNESSEE\n",
       "45         TX              TEXAS\n",
       "46         UT               UTAH\n",
       "47         VT            VERMONT\n",
       "48         VI     VIRGIN ISLANDS\n",
       "49         VA           VIRGINIA\n",
       "50         WV        W. VIRGINIA\n",
       "51         WA         WASHINGTON\n",
       "52         WI          WISCONSON\n",
       "53         WY            WYOMING\n",
       "54         99    All Other Codes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the states_codes.\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "state_codes = code_mapper(f_content, \"i94addrl\")\n",
    "list_map = list(map(list, state_codes.items()))\n",
    "state_codes_df = spark.createDataFrame(list_map, ['state_code', 'state'])\n",
    "state_codes_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD' 'MA' 'AL' 'CA' 'NJ' 'IL' 'AZ' 'MO' 'NC' 'PA' 'KS' 'FL' 'TX' 'VA' 'NV'\n",
      " 'CO' 'MI' 'CT' 'MN' 'UT' 'AR' 'TN' 'OK' 'WA' 'NY' 'GA' 'NE' 'KY' 'SC' 'LA'\n",
      " 'NM' 'IA' 'RI' 'PR' 'DC' 'WI' 'OR' 'NH' 'ND' 'DE' 'OH' 'ID' 'IN' 'AK' 'MS'\n",
      " 'HI' 'SD' 'ME' 'MT']\n"
     ]
    }
   ],
   "source": [
    "# Create user defined function to validate 'state' data\n",
    "valid_states = df_cities.toPandas()[\"State Code\"].unique()\n",
    "print(valid_states)\n",
    "\n",
    "@udf(StringType())\n",
    "def validate_state(s): \n",
    "    \"\"\" check for US states \"\"\"\n",
    "    if s in valid_states:\n",
    "        return s\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94addr\n",
       "0       AZ\n",
       "1       SC\n",
       "2       LA\n",
       "3       MN\n",
       "4       NJ\n",
       "5       DC\n",
       "6       OR\n",
       "7       VA\n",
       "8       RI\n",
       "9       KY\n",
       "10      NH\n",
       "11      MI\n",
       "12      NV\n",
       "13      WI\n",
       "14      ID\n",
       "15      CA\n",
       "16      CT\n",
       "17      NE\n",
       "18      MT\n",
       "19      NC\n",
       "20   other\n",
       "21      MD\n",
       "22      DE\n",
       "23      MO\n",
       "24      IL\n",
       "25      ME\n",
       "26      WA\n",
       "27      ND\n",
       "28      MS\n",
       "29      AL\n",
       "30      IN\n",
       "31      OH\n",
       "32      TN\n",
       "33      IA\n",
       "34      NM\n",
       "35      PA\n",
       "36      SD\n",
       "37      NY\n",
       "38      TX\n",
       "39      GA\n",
       "40      MA\n",
       "41      KS\n",
       "42      FL\n",
       "43      CO\n",
       "44      AK\n",
       "45      AR\n",
       "46      OK\n",
       "47      PR\n",
       "48      UT\n",
       "49      HI"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data with valid states\n",
    "df_immigration = df_immigration.withColumn(\"i94addr\" , validate_state(df_immigration.i94addr))\n",
    "df_immigration.select(\"i94addr\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94addr\n",
       "0       AZ\n",
       "1       SC\n",
       "2       LA\n",
       "3       MN\n",
       "4       NJ\n",
       "5       DC\n",
       "6       OR\n",
       "7       VA\n",
       "8       RI\n",
       "9       KY\n",
       "10      NH\n",
       "11      MI\n",
       "12      NV\n",
       "13      WI\n",
       "14      ID\n",
       "15      CA\n",
       "16      CT\n",
       "17      NE\n",
       "18      MT\n",
       "19      NC\n",
       "20      MD\n",
       "21      DE\n",
       "22      MO\n",
       "23      IL\n",
       "24      ME\n",
       "25      WA\n",
       "26      ND\n",
       "27      MS\n",
       "28      AL\n",
       "29      IN\n",
       "30      OH\n",
       "31      TN\n",
       "32      IA\n",
       "33      NM\n",
       "34      PA\n",
       "35      SD\n",
       "36      NY\n",
       "37      TX\n",
       "38      GA\n",
       "39      MA\n",
       "40      KS\n",
       "41      FL\n",
       "42      CO\n",
       "43      AK\n",
       "44      AR\n",
       "45      OK\n",
       "46      PR\n",
       "47      UT\n",
       "48      HI"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep US state data ( state != 'other')\n",
    "df_immigration = df_immigration.filter(df_immigration.i94addr != 'other') \n",
    "df_immigration.select(\"i94addr\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visapost</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>arrivalDate</th>\n",
       "      <th>departureDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  i94mode i94addr  i94bir  \\\n",
       "0  299.0  2016.0     4.0   103.0   103.0     NYC      1.0      NY    54.0   \n",
       "1  305.0  2016.0     4.0   103.0   103.0     NYC      1.0      NY    63.0   \n",
       "2  496.0  2016.0     4.0   103.0   103.0     CHI      1.0      IL    64.0   \n",
       "3  558.0  2016.0     4.0   103.0   103.0     SFR      1.0      CA    42.0   \n",
       "4  596.0  2016.0     4.0   103.0   103.0     NAS      1.0      FL    24.0   \n",
       "\n",
       "   i94visa visapost  biryear   dtaddto gender airline  fltno visatype  \\\n",
       "0      2.0     None   1962.0  06292016   None      OS  00087       WT   \n",
       "1      2.0     None   1953.0  06292016   None      OS  00087       WT   \n",
       "2      1.0     None   1952.0  06292016   None      OS  00065       WB   \n",
       "3      1.0     None   1974.0  06292016      M      LH  00454       WB   \n",
       "4      2.0     None   1992.0  06292016      M      UP  00221       WT   \n",
       "\n",
       "  arrivalDate departureDate  \n",
       "0  2016-04-01    2016-04-06  \n",
       "1  2016-04-01    2016-04-11  \n",
       "2  2016-04-01    2016-04-04  \n",
       "3  2016-04-01    2016-04-03  \n",
       "4  2016-04-01    2016-04-03  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert SAS date into Pyspark date.\n",
    "convert_date = F.udf(lambda x: (datetime(1960, 1, 1).date() + timedelta(x)).isoformat() if x else None)\n",
    "\n",
    "df_immigration = df_immigration.withColumn('arrivalDate', convert_date('arrdate'))\\\n",
    "                            .withColumn('departureDate', convert_date('depdate'))\\\n",
    "                            .drop('arrdate','depdate')\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visapost</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>arrivalDate</th>\n",
       "      <th>departureDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  i94mode i94addr  i94bir  \\\n",
       "0  299.0  2016.0     4.0   103.0   103.0     NYC      1.0      NY    54.0   \n",
       "1  305.0  2016.0     4.0   103.0   103.0     NYC      1.0      NY    63.0   \n",
       "2  496.0  2016.0     4.0   103.0   103.0     CHI      1.0      IL    64.0   \n",
       "3  558.0  2016.0     4.0   103.0   103.0     SFR      1.0      CA    42.0   \n",
       "4  596.0  2016.0     4.0   103.0   103.0     NAS      1.0      FL    24.0   \n",
       "\n",
       "   i94visa visapost  biryear   dtaddto gender airline  fltno visatype  \\\n",
       "0      2.0     None   1962.0  06292016   None      OS  00087       WT   \n",
       "1      2.0     None   1953.0  06292016   None      OS  00087       WT   \n",
       "2      1.0     None   1952.0  06292016   None      OS  00065       WB   \n",
       "3      1.0     None   1974.0  06292016      M      LH  00454       WB   \n",
       "4      2.0     None   1992.0  06292016      M      UP  00221       WT   \n",
       "\n",
       "  arrivalDate departureDate  \n",
       "0  2016-04-01    2016-04-06  \n",
       "1  2016-04-01    2016-04-11  \n",
       "2  2016-04-01    2016-04-04  \n",
       "3  2016-04-01    2016-04-03  \n",
       "4  2016-04-01    2016-04-03  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out there are rows with departure date being earlier than arrival date, which should be impossible. Let's clean this.\n",
    "df_immigration = df_immigration.where('departureDate > arrivalDate')\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>visa_issue_state</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_num</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>cic_id</th>\n",
       "      <th>arrive_year</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>arrive_month</th>\n",
       "      <th>citizen_country</th>\n",
       "      <th>resident_country</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>visa_class</th>\n",
       "      <th>mode</th>\n",
       "      <th>allowed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>299</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>54</td>\n",
       "      <td>1962</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>305</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>1953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHI</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>496</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SFR</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>558</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>42</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAS</td>\n",
       "      <td>FL</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>596</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>1992</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port arrive_state visa_issue_state gender airline flight_num visa_type  \\\n",
       "0  NYC           NY             None   None      OS      00087        WT   \n",
       "1  NYC           NY             None   None      OS      00087        WT   \n",
       "2  CHI           IL             None   None      OS      00065        WB   \n",
       "3  SFR           CA             None      M      LH      00454        WB   \n",
       "4  NAS           FL             None      M      UP      00221        WT   \n",
       "\n",
       "   cic_id  arrive_year arrival_date departure_date  arrive_month  \\\n",
       "0     299         2016   2016-04-01     2016-04-06             4   \n",
       "1     305         2016   2016-04-01     2016-04-11             4   \n",
       "2     496         2016   2016-04-01     2016-04-04             4   \n",
       "3     558         2016   2016-04-01     2016-04-03             4   \n",
       "4     596         2016   2016-04-01     2016-04-03             4   \n",
       "\n",
       "   citizen_country  resident_country  age  birth_year  visa_class  mode  \\\n",
       "0              103               103   54        1962           2     1   \n",
       "1              103               103   63        1953           2     1   \n",
       "2              103               103   64        1952           1     1   \n",
       "3              103               103   42        1974           1     1   \n",
       "4              103               103   24        1992           2     1   \n",
       "\n",
       "  allowed_date  \n",
       "0   2016-06-29  \n",
       "1   2016-06-29  \n",
       "2   2016-06-29  \n",
       "3   2016-06-29  \n",
       "4   2016-06-29  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix datatypes and rename columns\n",
    "df_immigration = df_immigration.withColumn(\"cic_id\",col(\"cicid\").cast(IntegerType())).drop(\"cicid\") \\\n",
    "            .withColumn(\"arrive_year\",col('i94yr').cast(IntegerType())).drop(\"i94yr\") \\\n",
    "            .withColumn(\"arrival_date\", col(\"arrivalDate\").cast(DateType())).drop(\"arrivalDate\") \\\n",
    "            .withColumn(\"departure_date\", col(\"departureDate\").cast(DateType())).drop(\"departureDate\") \\\n",
    "            .withColumn(\"arrive_month\",col('i94mon').cast(IntegerType())).drop(\"i94mon\") \\\n",
    "            .withColumn(\"citizen_country\",col('i94cit').cast(IntegerType())).drop(\"i94cit\") \\\n",
    "            .withColumn(\"resident_country\",col('i94res').cast(IntegerType())).drop(\"i94res\") \\\n",
    "            .withColumn(\"age\",col('i94bir').cast(IntegerType())).drop(\"i94bir\") \\\n",
    "            .withColumn(\"birth_year\",col('biryear').cast(IntegerType())).drop(\"biryear\") \\\n",
    "            .withColumn(\"visa_class\",col('i94visa').cast(IntegerType())).drop(\"i94visa\") \\\n",
    "            .withColumn(\"mode\",col('i94mode').cast(IntegerType())).drop(\"i94mode\") \\\n",
    "            .withColumn(\"allowed_date\", to_date(\"dtaddto\", \"MMddyyyy\")).drop(\"dtaddto\") \\\n",
    "            .withColumnRenamed(\"i94port\", \"port\") \\\n",
    "            .withColumnRenamed(\"i94addr\",\"arrive_state\") \\\n",
    "            .withColumnRenamed(\"fltno\",\"flight_num\") \\\n",
    "            .withColumnRenamed(\"visatype\",\"visa_type\") \\\n",
    "            .withColumnRenamed(\"visapost\",\"visa_issue_state\")\n",
    "\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>visa_issue_state</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_num</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>cic_id</th>\n",
       "      <th>arrive_year</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>arrive_month</th>\n",
       "      <th>citizen_country</th>\n",
       "      <th>resident_country</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>visa_class</th>\n",
       "      <th>mode</th>\n",
       "      <th>allowed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>299</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>54</td>\n",
       "      <td>1962</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>305</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>1953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHI</td>\n",
       "      <td>IL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>496</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SFR</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>558</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>42</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAS</td>\n",
       "      <td>FL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>596</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>1992</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port arrive_state visa_issue_state   gender airline flight_num visa_type  \\\n",
       "0  NYC           NY          unknown  unknown      OS      00087        WT   \n",
       "1  NYC           NY          unknown  unknown      OS      00087        WT   \n",
       "2  CHI           IL          unknown  unknown      OS      00065        WB   \n",
       "3  SFR           CA          unknown        M      LH      00454        WB   \n",
       "4  NAS           FL          unknown        M      UP      00221        WT   \n",
       "\n",
       "   cic_id  arrive_year arrival_date departure_date  arrive_month  \\\n",
       "0     299         2016   2016-04-01     2016-04-06             4   \n",
       "1     305         2016   2016-04-01     2016-04-11             4   \n",
       "2     496         2016   2016-04-01     2016-04-04             4   \n",
       "3     558         2016   2016-04-01     2016-04-03             4   \n",
       "4     596         2016   2016-04-01     2016-04-03             4   \n",
       "\n",
       "   citizen_country  resident_country  age  birth_year  visa_class  mode  \\\n",
       "0              103               103   54        1962           2     1   \n",
       "1              103               103   63        1953           2     1   \n",
       "2              103               103   64        1952           1     1   \n",
       "3              103               103   42        1974           1     1   \n",
       "4              103               103   24        1992           2     1   \n",
       "\n",
       "  allowed_date  \n",
       "0   2016-06-29  \n",
       "1   2016-06-29  \n",
       "2   2016-06-29  \n",
       "3   2016-06-29  \n",
       "4   2016-06-29  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling missing/NaN values with (unknown)\n",
    "df_immigration = df_immigration.na.fill(value='unknown',subset=[\"port\",\"arrive_state\",\"visa_issue_state\",\"gender\",\"airline\"])\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.select('visa_class').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = df_immigration.withColumn('visa_class', when(df_immigration.visa_class == 1, 'Business' )\\\n",
    "                                                         .when(df_immigration.visa_class == 2, 'Pleasure')\\\n",
    "                                                         .when(df_immigration.visa_class == 3, 'Student' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = df_immigration.withColumn('mode', when(df_immigration.mode == 1, 'Air' )\\\n",
    "                                                    .when(df_immigration.mode == 2, 'Sea')\\\n",
    "                                                    .when(df_immigration.mode == 3, 'Land' )\\\n",
    "                                                    .when(df_immigration.mode == 9, 'Not reported' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>visa_issue_state</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_num</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>cic_id</th>\n",
       "      <th>arrive_year</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>arrive_month</th>\n",
       "      <th>citizen_country</th>\n",
       "      <th>resident_country</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>visa_class</th>\n",
       "      <th>mode</th>\n",
       "      <th>allowed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>299</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>54</td>\n",
       "      <td>1962</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>OS</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>305</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>1953</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHI</td>\n",
       "      <td>IL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>496</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>1952</td>\n",
       "      <td>Business</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SFR</td>\n",
       "      <td>CA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>558</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>42</td>\n",
       "      <td>1974</td>\n",
       "      <td>Business</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAS</td>\n",
       "      <td>FL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>596</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>1992</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-06-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port arrive_state visa_issue_state   gender airline flight_num visa_type  \\\n",
       "0  NYC           NY          unknown  unknown      OS      00087        WT   \n",
       "1  NYC           NY          unknown  unknown      OS      00087        WT   \n",
       "2  CHI           IL          unknown  unknown      OS      00065        WB   \n",
       "3  SFR           CA          unknown        M      LH      00454        WB   \n",
       "4  NAS           FL          unknown        M      UP      00221        WT   \n",
       "\n",
       "   cic_id  arrive_year arrival_date departure_date  arrive_month  \\\n",
       "0     299         2016   2016-04-01     2016-04-06             4   \n",
       "1     305         2016   2016-04-01     2016-04-11             4   \n",
       "2     496         2016   2016-04-01     2016-04-04             4   \n",
       "3     558         2016   2016-04-01     2016-04-03             4   \n",
       "4     596         2016   2016-04-01     2016-04-03             4   \n",
       "\n",
       "   citizen_country  resident_country  age  birth_year visa_class mode  \\\n",
       "0              103               103   54        1962   Pleasure  Air   \n",
       "1              103               103   63        1953   Pleasure  Air   \n",
       "2              103               103   64        1952   Business  Air   \n",
       "3              103               103   42        1974   Business  Air   \n",
       "4              103               103   24        1992   Pleasure  Air   \n",
       "\n",
       "  allowed_date  \n",
       "0   2016-06-29  \n",
       "1   2016-06-29  \n",
       "2   2016-06-29  \n",
       "3   2016-06-29  \n",
       "4   2016-06-29  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration.select(\"visa_issue_state\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code                                            country\n",
       "0          582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1          236                                        AFGHANISTAN\n",
       "2          101                                            ALBANIA\n",
       "3          316                                            ALGERIA\n",
       "4          102                                            ANDORRA"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the country_codes.\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "country_codes = code_mapper(f_content, \"i94cntyl\")\n",
    "list_map = list(map(list, country_codes.items()))\n",
    "country_codes_df = spark.createDataFrame(list_map, ['country_code', 'country'])\n",
    "country_codes_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country_code: int, country: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_df.withColumn(\"country_code\", col(\"country_code\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>visa_issue_state</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_num</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>cic_id</th>\n",
       "      <th>arrive_year</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>arrive_month</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>visa_class</th>\n",
       "      <th>mode</th>\n",
       "      <th>allowed_date</th>\n",
       "      <th>citizen_country_name</th>\n",
       "      <th>resident_country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC</td>\n",
       "      <td>CT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>CX</td>\n",
       "      <td>00840</td>\n",
       "      <td>WT</td>\n",
       "      <td>2018851</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1986</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>None</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HHW</td>\n",
       "      <td>HI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NQ</td>\n",
       "      <td>00182</td>\n",
       "      <td>WT</td>\n",
       "      <td>1835040</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>1968</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-08</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HHW</td>\n",
       "      <td>HI</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NQ</td>\n",
       "      <td>00182</td>\n",
       "      <td>WT</td>\n",
       "      <td>1835041</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-08</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FTL</td>\n",
       "      <td>IL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NH</td>\n",
       "      <td>00012</td>\n",
       "      <td>WT</td>\n",
       "      <td>2352309</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1989</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-11</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC</td>\n",
       "      <td>FL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>00172</td>\n",
       "      <td>WT</td>\n",
       "      <td>680670</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>1955</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NYC</td>\n",
       "      <td>FL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>F</td>\n",
       "      <td>DL</td>\n",
       "      <td>00172</td>\n",
       "      <td>WT</td>\n",
       "      <td>680669</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>1953</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LVG</td>\n",
       "      <td>CA</td>\n",
       "      <td>KLL</td>\n",
       "      <td>M</td>\n",
       "      <td>KE</td>\n",
       "      <td>00005</td>\n",
       "      <td>B2</td>\n",
       "      <td>1422788</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>1955</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NYC</td>\n",
       "      <td>PA</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>CX</td>\n",
       "      <td>00830</td>\n",
       "      <td>WT</td>\n",
       "      <td>1650443</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1983</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-07-07</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>CX</td>\n",
       "      <td>00830</td>\n",
       "      <td>B2</td>\n",
       "      <td>2951936</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1987</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>MAURITANIA</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NYC</td>\n",
       "      <td>FL</td>\n",
       "      <td>RNG</td>\n",
       "      <td>M</td>\n",
       "      <td>SQ</td>\n",
       "      <td>00026</td>\n",
       "      <td>B1</td>\n",
       "      <td>431506</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1996</td>\n",
       "      <td>Business</td>\n",
       "      <td>Air</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>None</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port arrive_state visa_issue_state   gender airline flight_num visa_type  \\\n",
       "0  NYC           CT          unknown        M      CX      00840        WT   \n",
       "1  HHW           HI          unknown  unknown      NQ      00182        WT   \n",
       "2  HHW           HI          unknown  unknown      NQ      00182        WT   \n",
       "3  FTL           IL          unknown  unknown      NH      00012        WT   \n",
       "4  NYC           FL          unknown        M      DL      00172        WT   \n",
       "5  NYC           FL          unknown        F      DL      00172        WT   \n",
       "6  LVG           CA              KLL        M      KE      00005        B2   \n",
       "7  NYC           PA          unknown        M      CX      00830        WT   \n",
       "8  NYC           NY          unknown        M      CX      00830        B2   \n",
       "9  NYC           FL              RNG        M      SQ      00026        B1   \n",
       "\n",
       "    cic_id  arrive_year arrival_date departure_date  arrive_month  age  \\\n",
       "0  2018851         2016   2016-04-11     2016-04-23             4   30   \n",
       "1  1835040         2016   2016-04-10     2016-04-19             4   48   \n",
       "2  1835041         2016   2016-04-10     2016-04-19             4    9   \n",
       "3  2352309         2016   2016-04-13     2016-04-17             4   27   \n",
       "4   680670         2016   2016-04-04     2016-04-11             4   61   \n",
       "5   680669         2016   2016-04-04     2016-04-11             4   63   \n",
       "6  1422788         2016   2016-04-08     2016-04-17             4   61   \n",
       "7  1650443         2016   2016-04-09     2016-04-19             4   33   \n",
       "8  2951936         2016   2016-04-15     2016-04-29             4   29   \n",
       "9   431506         2016   2016-04-02     2016-06-14             4   20   \n",
       "\n",
       "   birth_year visa_class mode allowed_date citizen_country_name  \\\n",
       "0        1986   Pleasure  Air   2016-07-09                 None   \n",
       "1        1968   Pleasure  Air   2016-07-08                JAPAN   \n",
       "2        2007   Pleasure  Air   2016-07-08                JAPAN   \n",
       "3        1989   Pleasure  Air   2016-07-11                JAPAN   \n",
       "4        1955   Pleasure  Air   2016-07-02            SINGAPORE   \n",
       "5        1953   Pleasure  Air   2016-07-02            SINGAPORE   \n",
       "6        1955   Pleasure  Air   2016-10-07             MALAYSIA   \n",
       "7        1983   Pleasure  Air   2016-07-07            AUSTRALIA   \n",
       "8        1987   Pleasure  Air   2016-10-14           MAURITANIA   \n",
       "9        1996   Business  Air   2016-10-01                 None   \n",
       "\n",
       "  resident_country_name  \n",
       "0                 BURMA  \n",
       "1                 BURMA  \n",
       "2                 BURMA  \n",
       "3                 BURMA  \n",
       "4                 BURMA  \n",
       "5                 BURMA  \n",
       "6                 BURMA  \n",
       "7                 BURMA  \n",
       "8                 BURMA  \n",
       "9                 BURMA  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the immigration df with the country_codes_df\n",
    "\n",
    "df_immigration = df_immigration.join(country_codes_df, df_immigration['citizen_country'] == country_codes_df.country_code, \\\n",
    "                                     how = 'left')\\\n",
    "                             .withColumnRenamed('country', 'citizen_country_name')\\\n",
    "                             .drop('country_code')\\\n",
    "                             .drop('citizen_country')\\\n",
    "                             .join(country_codes_df, df_immigration['resident_country'] == country_codes_df.country_code, \\\n",
    "                                   how = 'left')\\\n",
    "                             .withColumnRenamed('country', 'resident_country_name')\\\n",
    "                             .drop('country_code')\\\n",
    "                             .drop('resident_country')\n",
    "\n",
    "df_immigration.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Airport Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06IN</td>\n",
       "      <td>closed</td>\n",
       "      <td>Ellis Fly-In Airport</td>\n",
       "      <td>575</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Blackhawk</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-87.303596, 39.282799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06VA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mount Horeb Field</td>\n",
       "      <td>1160</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-VA</td>\n",
       "      <td>Grottoes</td>\n",
       "      <td>06VA</td>\n",
       "      <td>None</td>\n",
       "      <td>06VA</td>\n",
       "      <td>-78.85530090332031, 38.249000549316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0LA0</td>\n",
       "      <td>heliport</td>\n",
       "      <td>West Hackberry Heliport</td>\n",
       "      <td>10</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>Hackberry</td>\n",
       "      <td>0LA0</td>\n",
       "      <td>None</td>\n",
       "      <td>0LA0</td>\n",
       "      <td>-93.40019989013672, 30.008499145507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0MD6</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Walters Airport</td>\n",
       "      <td>750</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MD</td>\n",
       "      <td>Mount Airy</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>None</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>-77.10579681396484, 39.38119888305664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0OH7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Apple Airport</td>\n",
       "      <td>1000</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>Piqua</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>None</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>-84.1718978881836, 40.1432991027832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                     name elevation_ft continent  \\\n",
       "0  06IN         closed     Ellis Fly-In Airport          575        NA   \n",
       "1  06VA  small_airport        Mount Horeb Field         1160        NA   \n",
       "2  0LA0       heliport  West Hackberry Heliport           10        NA   \n",
       "3  0MD6  small_airport          Walters Airport          750        NA   \n",
       "4  0OH7  small_airport            Apple Airport         1000        NA   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US      US-IN    Blackhawk     None      None       None   \n",
       "1          US      US-VA     Grottoes     06VA      None       06VA   \n",
       "2          US      US-LA    Hackberry     0LA0      None       0LA0   \n",
       "3          US      US-MD   Mount Airy     0MD6      None       0MD6   \n",
       "4          US      US-OH        Piqua     0OH7      None       0OH7   \n",
       "\n",
       "                              coordinates  \n",
       "0                   -87.303596, 39.282799  \n",
       "1  -78.85530090332031, 38.249000549316406  \n",
       "2  -93.40019989013672, 30.008499145507812  \n",
       "3   -77.10579681396484, 39.38119888305664  \n",
       "4     -84.1718978881836, 40.1432991027832  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping any rows with duplicate ident.\n",
    "df_airport = df_airport.dropDuplicates([\"ident\"])\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06IN</td>\n",
       "      <td>closed</td>\n",
       "      <td>Ellis Fly-In Airport</td>\n",
       "      <td>575</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Blackhawk</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-87.303596, 39.282799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06VA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mount Horeb Field</td>\n",
       "      <td>1160</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-VA</td>\n",
       "      <td>Grottoes</td>\n",
       "      <td>06VA</td>\n",
       "      <td>None</td>\n",
       "      <td>06VA</td>\n",
       "      <td>-78.85530090332031, 38.249000549316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0LA0</td>\n",
       "      <td>heliport</td>\n",
       "      <td>West Hackberry Heliport</td>\n",
       "      <td>10</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>Hackberry</td>\n",
       "      <td>0LA0</td>\n",
       "      <td>None</td>\n",
       "      <td>0LA0</td>\n",
       "      <td>-93.40019989013672, 30.008499145507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0MD6</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Walters Airport</td>\n",
       "      <td>750</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MD</td>\n",
       "      <td>Mount Airy</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>None</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>-77.10579681396484, 39.38119888305664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0OH7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Apple Airport</td>\n",
       "      <td>1000</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>Piqua</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>None</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>-84.1718978881836, 40.1432991027832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                     name elevation_ft continent  \\\n",
       "0  06IN         closed     Ellis Fly-In Airport          575        NA   \n",
       "1  06VA  small_airport        Mount Horeb Field         1160        NA   \n",
       "2  0LA0       heliport  West Hackberry Heliport           10        NA   \n",
       "3  0MD6  small_airport          Walters Airport          750        NA   \n",
       "4  0OH7  small_airport            Apple Airport         1000        NA   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US      US-IN    Blackhawk     None      None       None   \n",
       "1          US      US-VA     Grottoes     06VA      None       06VA   \n",
       "2          US      US-LA    Hackberry     0LA0      None       0LA0   \n",
       "3          US      US-MD   Mount Airy     0MD6      None       0MD6   \n",
       "4          US      US-OH        Piqua     0OH7      None       0OH7   \n",
       "\n",
       "                              coordinates  \n",
       "0                   -87.303596, 39.282799  \n",
       "1  -78.85530090332031, 38.249000549316406  \n",
       "2  -93.40019989013672, 30.008499145507812  \n",
       "3   -77.10579681396484, 39.38119888305664  \n",
       "4     -84.1718978881836, 40.1432991027832  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop rows with 100% missing values.\n",
    "\n",
    "df_airport = df_airport.dropna(how='all')\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06IN</td>\n",
       "      <td>closed</td>\n",
       "      <td>Ellis Fly-In Airport</td>\n",
       "      <td>575</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Blackhawk</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-87.303596</td>\n",
       "      <td>39.282799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06VA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mount Horeb Field</td>\n",
       "      <td>1160</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-VA</td>\n",
       "      <td>Grottoes</td>\n",
       "      <td>06VA</td>\n",
       "      <td>None</td>\n",
       "      <td>06VA</td>\n",
       "      <td>-78.85530090332031</td>\n",
       "      <td>38.249000549316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0LA0</td>\n",
       "      <td>heliport</td>\n",
       "      <td>West Hackberry Heliport</td>\n",
       "      <td>10</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>Hackberry</td>\n",
       "      <td>0LA0</td>\n",
       "      <td>None</td>\n",
       "      <td>0LA0</td>\n",
       "      <td>-93.40019989013672</td>\n",
       "      <td>30.008499145507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0MD6</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Walters Airport</td>\n",
       "      <td>750</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MD</td>\n",
       "      <td>Mount Airy</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>None</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>-77.10579681396484</td>\n",
       "      <td>39.38119888305664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0OH7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Apple Airport</td>\n",
       "      <td>1000</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>Piqua</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>None</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>-84.1718978881836</td>\n",
       "      <td>40.1432991027832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                     name elevation_ft continent  \\\n",
       "0  06IN         closed     Ellis Fly-In Airport          575        NA   \n",
       "1  06VA  small_airport        Mount Horeb Field         1160        NA   \n",
       "2  0LA0       heliport  West Hackberry Heliport           10        NA   \n",
       "3  0MD6  small_airport          Walters Airport          750        NA   \n",
       "4  0OH7  small_airport            Apple Airport         1000        NA   \n",
       "\n",
       "  iso_country iso_region municipality gps_code iata_code local_code  \\\n",
       "0          US      US-IN    Blackhawk     None      None       None   \n",
       "1          US      US-VA     Grottoes     06VA      None       06VA   \n",
       "2          US      US-LA    Hackberry     0LA0      None       0LA0   \n",
       "3          US      US-MD   Mount Airy     0MD6      None       0MD6   \n",
       "4          US      US-OH        Piqua     0OH7      None       0OH7   \n",
       "\n",
       "             latitude            longitude  \n",
       "0          -87.303596            39.282799  \n",
       "1  -78.85530090332031   38.249000549316406  \n",
       "2  -93.40019989013672   30.008499145507812  \n",
       "3  -77.10579681396484    39.38119888305664  \n",
       "4   -84.1718978881836     40.1432991027832  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split coordinates column into latitude and longitude\n",
    "\n",
    "df_airport=df_airport.withColumn('latitude',split(df_airport['coordinates'],',').getItem(0))\\\n",
    "                    .withColumn('longitude',split(df_airport['coordinates'],',').getItem(1))\\\n",
    "                    .drop('coordinates')\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          type|\n",
      "+--------------+\n",
      "| large_airport|\n",
      "|   balloonport|\n",
      "| seaplane_base|\n",
      "|      heliport|\n",
      "|        closed|\n",
      "|medium_airport|\n",
      "| small_airport|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.select('type').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          type|\n",
      "+--------------+\n",
      "| large_airport|\n",
      "|medium_airport|\n",
      "| small_airport|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean airports dataset by filter only type = (small / medium / large) airports\n",
    "df_airport = df_airport.filter( (df_airport[\"type\"] == \"small_airport\") | (df_airport[\"type\"]==\"medium_airport\") | (df_airport[\"type\"] == \"large_airport\") ) \n",
    "df_airport.select('type').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06VA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Mount Horeb Field</td>\n",
       "      <td>1160</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Grottoes</td>\n",
       "      <td>06VA</td>\n",
       "      <td>None</td>\n",
       "      <td>06VA</td>\n",
       "      <td>-78.85530090332031</td>\n",
       "      <td>38.249000549316406</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0MD6</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Walters Airport</td>\n",
       "      <td>750</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Mount Airy</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>None</td>\n",
       "      <td>0MD6</td>\n",
       "      <td>-77.10579681396484</td>\n",
       "      <td>39.38119888305664</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0OH7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Apple Airport</td>\n",
       "      <td>1000</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Piqua</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>None</td>\n",
       "      <td>0OH7</td>\n",
       "      <td>-84.1718978881836</td>\n",
       "      <td>40.1432991027832</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0OK9</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crystal Airport</td>\n",
       "      <td>1016</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Jennings</td>\n",
       "      <td>0OK9</td>\n",
       "      <td>None</td>\n",
       "      <td>0OK9</td>\n",
       "      <td>-96.63700103759766</td>\n",
       "      <td>36.213401794433594</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16KY</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Praise God Airport</td>\n",
       "      <td>1070</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Carter</td>\n",
       "      <td>16KY</td>\n",
       "      <td>None</td>\n",
       "      <td>16KY</td>\n",
       "      <td>-83.1227035522461</td>\n",
       "      <td>38.444000244140625</td>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                name elevation_ft continent iso_country  \\\n",
       "0  06VA  small_airport   Mount Horeb Field         1160        NA          US   \n",
       "1  0MD6  small_airport     Walters Airport          750        NA          US   \n",
       "2  0OH7  small_airport       Apple Airport         1000        NA          US   \n",
       "3  0OK9  small_airport     Crystal Airport         1016        NA          US   \n",
       "4  16KY  small_airport  Praise God Airport         1070        NA          US   \n",
       "\n",
       "  municipality gps_code iata_code local_code            latitude  \\\n",
       "0     Grottoes     06VA      None       06VA  -78.85530090332031   \n",
       "1   Mount Airy     0MD6      None       0MD6  -77.10579681396484   \n",
       "2        Piqua     0OH7      None       0OH7   -84.1718978881836   \n",
       "3     Jennings     0OK9      None       0OK9  -96.63700103759766   \n",
       "4       Carter     16KY      None       16KY   -83.1227035522461   \n",
       "\n",
       "             longitude state  \n",
       "0   38.249000549316406    VA  \n",
       "1    39.38119888305664    MD  \n",
       "2     40.1432991027832    OH  \n",
       "3   36.213401794433594    OK  \n",
       "4   38.444000244140625    KY  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get state code from iso_region\n",
    "df_airport = df_airport.withColumn('state', split(df_airport['iso_region'], '-').getItem(1))\n",
    "df_airport.limit(5).toPandas()\n",
    "df_airport = df_airport.drop('iso_region')\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|iata_code|\n",
      "+---------+\n",
      "|      DWR|\n",
      "|      KEB|\n",
      "|      MIZ|\n",
      "|      VCH|\n",
      "|      BGM|\n",
      "|      UAB|\n",
      "|      SCW|\n",
      "|      CCK|\n",
      "|      GIS|\n",
      "|      TNP|\n",
      "|      KGL|\n",
      "|      KMU|\n",
      "|      FMY|\n",
      "|      LEN|\n",
      "|      LEB|\n",
      "|      PMK|\n",
      "|      PKE|\n",
      "|      GZW|\n",
      "|      SGT|\n",
      "|      CNU|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since df_immigration.port is df_airport.iata_code, so we don't need null in it.\n",
    "# Drop rows with missing values in iata_code.\n",
    "\n",
    "df_airport = df_airport.dropna(how='all',subset=['iata_code'])\n",
    "df_airport.select('iata_code').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.select('iata_code').where('iata_code IS NULL').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8699"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KAVP</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Wilkes Barre Scranton International Airport</td>\n",
       "      <td>962</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Wilkes-Barre/Scranton</td>\n",
       "      <td>KAVP</td>\n",
       "      <td>AVP</td>\n",
       "      <td>AVP</td>\n",
       "      <td>-75.72339630130001</td>\n",
       "      <td>41.338500976599995</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KAXS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Altus Quartz Mountain Regional Airport</td>\n",
       "      <td>1433</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Altus</td>\n",
       "      <td>KAXS</td>\n",
       "      <td>AXS</td>\n",
       "      <td>AXS</td>\n",
       "      <td>-99.3385</td>\n",
       "      <td>34.697952</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KCKA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Kegelman AF Aux Field</td>\n",
       "      <td>1202</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>KCKA</td>\n",
       "      <td>CKA</td>\n",
       "      <td>CKA</td>\n",
       "      <td>-98.1231002808</td>\n",
       "      <td>36.7439002991</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KEB</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nanwalek Airport</td>\n",
       "      <td>27</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Nanwalek</td>\n",
       "      <td>KEB</td>\n",
       "      <td>KEB</td>\n",
       "      <td>KEB</td>\n",
       "      <td>-151.925003052</td>\n",
       "      <td>59.3521003723</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KFSI</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Henry Post Army Air Field (Fort Sill)</td>\n",
       "      <td>1189</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Fort Sill</td>\n",
       "      <td>KFSI</td>\n",
       "      <td>FSI</td>\n",
       "      <td>FSI</td>\n",
       "      <td>-98.40219879</td>\n",
       "      <td>34.64979935</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident            type                                         name  \\\n",
       "0  KAVP  medium_airport  Wilkes Barre Scranton International Airport   \n",
       "1  KAXS   small_airport       Altus Quartz Mountain Regional Airport   \n",
       "2  KCKA   small_airport                        Kegelman AF Aux Field   \n",
       "3   KEB   small_airport                             Nanwalek Airport   \n",
       "4  KFSI  medium_airport        Henry Post Army Air Field (Fort Sill)   \n",
       "\n",
       "  elevation_ft continent iso_country           municipality gps_code  \\\n",
       "0          962        NA          US  Wilkes-Barre/Scranton     KAVP   \n",
       "1         1433        NA          US                  Altus     KAXS   \n",
       "2         1202        NA          US               Cherokee     KCKA   \n",
       "3           27        NA          US               Nanwalek      KEB   \n",
       "4         1189        NA          US              Fort Sill     KFSI   \n",
       "\n",
       "  iata_code local_code            latitude            longitude state  \n",
       "0       AVP        AVP  -75.72339630130001   41.338500976599995    PA  \n",
       "1       AXS        AXS            -99.3385            34.697952    OK  \n",
       "2       CKA        CKA      -98.1231002808        36.7439002991    OK  \n",
       "3       KEB        KEB      -151.925003052        59.3521003723    AK  \n",
       "4       FSI        FSI        -98.40219879          34.64979935    OK  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean airports dataset by filter only iso_country = US\n",
    "df_airport = df_airport.filter(df_airport[\"iso_country\"] == \"US\")\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### us-cities-demographics Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with 100% missing values.\n",
    "df_cities = df_cities.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504</td>\n",
       "      <td>45760</td>\n",
       "      <td>85264</td>\n",
       "      <td>4176</td>\n",
       "      <td>15842</td>\n",
       "      <td>2.94</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>63666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>35.8</td>\n",
       "      <td>38747</td>\n",
       "      <td>38309</td>\n",
       "      <td>77056</td>\n",
       "      <td>780</td>\n",
       "      <td>34322</td>\n",
       "      <td>4.13</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.6</td>\n",
       "      <td>1149686</td>\n",
       "      <td>1148942</td>\n",
       "      <td>2298628</td>\n",
       "      <td>71898</td>\n",
       "      <td>696210</td>\n",
       "      <td>2.66</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>173854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>32.7</td>\n",
       "      <td>47835</td>\n",
       "      <td>53809</td>\n",
       "      <td>101644</td>\n",
       "      <td>9421</td>\n",
       "      <td>11888</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NM</td>\n",
       "      <td>White</td>\n",
       "      <td>91201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Missouri City</td>\n",
       "      <td>Texas</td>\n",
       "      <td>37.2</td>\n",
       "      <td>34932</td>\n",
       "      <td>36846</td>\n",
       "      <td>71778</td>\n",
       "      <td>4274</td>\n",
       "      <td>18556</td>\n",
       "      <td>3.03</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>17854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City       State Median Age Male Population Female Population  \\\n",
       "0        Alafaya     Florida       33.5           39504             45760   \n",
       "1   Baldwin Park  California       35.8           38747             38309   \n",
       "2        Houston       Texas       32.6         1149686           1148942   \n",
       "3     Las Cruces  New Mexico       32.7           47835             53809   \n",
       "4  Missouri City       Texas       37.2           34932             36846   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0            85264               4176        15842                   2.94   \n",
       "1            77056                780        34322                   4.13   \n",
       "2          2298628              71898       696210                   2.66   \n",
       "3           101644               9421        11888                   2.58   \n",
       "4            71778               4274        18556                   3.03   \n",
       "\n",
       "  State Code                       Race   Count  \n",
       "0         FL                      White   63666  \n",
       "1         CA  Black or African-American    1560  \n",
       "2         TX                      Asian  173854  \n",
       "3         NM                      White   91201  \n",
       "4         TX                      Asian   17854  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping duplicate rows.\n",
    "df_cities = df_cities.dropDuplicates(['City', 'State', 'Race'])\n",
    "df_cities.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatypes, format column names \n",
    "df_cities = df_cities.withColumn(\"median_age\",col(\"Median Age\").cast(FloatType())).drop(\"Median Age\") \\\n",
    "                    .withColumn(\"male_population\",col(\"Male Population\").cast(IntegerType())).drop(\"Male Population\") \\\n",
    "                    .withColumn(\"female_population\",col(\"Female Population\").cast(IntegerType())).drop(\"Female Population\") \\\n",
    "                    .withColumn(\"total_population\",col(\"Total Population\").cast(IntegerType())).drop(\"Total Population\") \\\n",
    "                    .withColumn(\"veterans_num\",col(\"Number of Veterans\").cast(IntegerType())).drop(\"Number of Veterans\") \\\n",
    "                    .withColumn(\"foreign_born_population\",col(\"Foreign-born\").cast(IntegerType())).drop(\"Foreign-born\") \\\n",
    "                    .withColumn(\"avg_household_size\",col(\"Average Household Size\").cast(FloatType())).drop(\"Average Household Size\") \\\n",
    "                    .withColumn(\"count\",col(\"Count\").cast(IntegerType())) \\\n",
    "                    .withColumnRenamed(\"City\", \"city\") \\\n",
    "                    .withColumnRenamed(\"State\", \"state\") \\\n",
    "                    .withColumnRenamed(\"State Code\", \"state_code\") \\\n",
    "                    .withColumnRenamed(\"Race\", \"race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table to make each race population into seperate columns, change column names\n",
    "df_cities = df_cities.groupBy(col(\"city\"),col(\"state\"),col(\"median_age\"),col(\"male_population\"),col(\"female_population\")\\\n",
    "                            ,col(\"total_population\"),col(\"veterans_num\"),col(\"foreign_born_population\"),col(\"avg_household_size\") \\\n",
    "                            ,col(\"state_code\")) \\\n",
    "                    .pivot(\"race\").agg(sum(\"count\")) \\\n",
    "                    .fillna({\"American Indian and Alaska Native\": 0,\n",
    "                     \"Asian\": 0,\n",
    "                     \"Black or African-American\": 0,\n",
    "                     \"Hispanic or Latino\": 0,\n",
    "                     \"White\": 0}) \\\n",
    "                    .withColumnRenamed(\"American Indian and Alaska Native\", \"american_indian_alaska_native\") \\\n",
    "                    .withColumnRenamed(\"Asian\",\"asian\") \\\n",
    "                    .withColumnRenamed(\"Black or African-American\",\"african_american\") \\\n",
    "                    .withColumnRenamed(\"Hispanic or Latino\",\"hispanic_latino\") \\\n",
    "                    .withColumnRenamed(\"White\",\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>veterans_num</th>\n",
       "      <th>foreign_born_population</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>american_indian_alaska_native</th>\n",
       "      <th>asian</th>\n",
       "      <th>african_american</th>\n",
       "      <th>hispanic_latino</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>91275</td>\n",
       "      <td>103030</td>\n",
       "      <td>194305</td>\n",
       "      <td>11939</td>\n",
       "      <td>7234</td>\n",
       "      <td>2.40</td>\n",
       "      <td>AL</td>\n",
       "      <td>2816</td>\n",
       "      <td>5518</td>\n",
       "      <td>96397</td>\n",
       "      <td>5229</td>\n",
       "      <td>93755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>4759</td>\n",
       "      <td>18191</td>\n",
       "      <td>3430</td>\n",
       "      <td>61869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>47293</td>\n",
       "      <td>51045</td>\n",
       "      <td>98338</td>\n",
       "      <td>3647</td>\n",
       "      <td>4706</td>\n",
       "      <td>2.67</td>\n",
       "      <td>AL</td>\n",
       "      <td>261</td>\n",
       "      <td>2733</td>\n",
       "      <td>42331</td>\n",
       "      <td>2475</td>\n",
       "      <td>52603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dothan</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.900002</td>\n",
       "      <td>32172</td>\n",
       "      <td>35364</td>\n",
       "      <td>67536</td>\n",
       "      <td>6334</td>\n",
       "      <td>1699</td>\n",
       "      <td>2.59</td>\n",
       "      <td>AL</td>\n",
       "      <td>656</td>\n",
       "      <td>1175</td>\n",
       "      <td>23243</td>\n",
       "      <td>1704</td>\n",
       "      <td>43516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huntsville</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.099998</td>\n",
       "      <td>91764</td>\n",
       "      <td>97350</td>\n",
       "      <td>189114</td>\n",
       "      <td>16637</td>\n",
       "      <td>12691</td>\n",
       "      <td>2.18</td>\n",
       "      <td>AL</td>\n",
       "      <td>1755</td>\n",
       "      <td>6566</td>\n",
       "      <td>61561</td>\n",
       "      <td>10887</td>\n",
       "      <td>121904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>35.599998</td>\n",
       "      <td>102122</td>\n",
       "      <td>112789</td>\n",
       "      <td>214911</td>\n",
       "      <td>13212</td>\n",
       "      <td>8258</td>\n",
       "      <td>2.21</td>\n",
       "      <td>AL</td>\n",
       "      <td>1319</td>\n",
       "      <td>1500</td>\n",
       "      <td>157985</td>\n",
       "      <td>8940</td>\n",
       "      <td>51728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>94582</td>\n",
       "      <td>106004</td>\n",
       "      <td>200586</td>\n",
       "      <td>14955</td>\n",
       "      <td>9337</td>\n",
       "      <td>2.41</td>\n",
       "      <td>AL</td>\n",
       "      <td>1277</td>\n",
       "      <td>6518</td>\n",
       "      <td>121360</td>\n",
       "      <td>6648</td>\n",
       "      <td>73545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city    state  median_age  male_population  female_population  \\\n",
       "0      Mobile  Alabama   38.000000            91275             103030   \n",
       "1      Hoover  Alabama   38.500000            38040              46799   \n",
       "2  Tuscaloosa  Alabama   29.100000            47293              51045   \n",
       "3      Dothan  Alabama   38.900002            32172              35364   \n",
       "4  Huntsville  Alabama   38.099998            91764              97350   \n",
       "5  Birmingham  Alabama   35.599998           102122             112789   \n",
       "6  Montgomery  Alabama   35.400002            94582             106004   \n",
       "\n",
       "   total_population  veterans_num  foreign_born_population  \\\n",
       "0            194305         11939                     7234   \n",
       "1             84839          4819                     8229   \n",
       "2             98338          3647                     4706   \n",
       "3             67536          6334                     1699   \n",
       "4            189114         16637                    12691   \n",
       "5            214911         13212                     8258   \n",
       "6            200586         14955                     9337   \n",
       "\n",
       "   avg_household_size state_code  american_indian_alaska_native  asian  \\\n",
       "0                2.40         AL                           2816   5518   \n",
       "1                2.58         AL                              0   4759   \n",
       "2                2.67         AL                            261   2733   \n",
       "3                2.59         AL                            656   1175   \n",
       "4                2.18         AL                           1755   6566   \n",
       "5                2.21         AL                           1319   1500   \n",
       "6                2.41         AL                           1277   6518   \n",
       "\n",
       "   african_american  hispanic_latino   white  \n",
       "0             96397             5229   93755  \n",
       "1             18191             3430   61869  \n",
       "2             42331             2475   52603  \n",
       "3             23243             1704   43516  \n",
       "4             61561            10887  121904  \n",
       "5            157985             8940   51728  \n",
       "6            121360             6648   73545  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.sort(\"state\").limit(7).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>veterans_num</th>\n",
       "      <th>foreign_born_population</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>american_indian_alaska_native</th>\n",
       "      <th>asian</th>\n",
       "      <th>african_american</th>\n",
       "      <th>hispanic_latino</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT</td>\n",
       "      <td>Montana</td>\n",
       "      <td>35</td>\n",
       "      <td>87707</td>\n",
       "      <td>93587</td>\n",
       "      <td>181294</td>\n",
       "      <td>13854</td>\n",
       "      <td>5977</td>\n",
       "      <td>2</td>\n",
       "      <td>9684</td>\n",
       "      <td>4165</td>\n",
       "      <td>3349</td>\n",
       "      <td>10000</td>\n",
       "      <td>169026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>33</td>\n",
       "      <td>1466105</td>\n",
       "      <td>1594094</td>\n",
       "      <td>3060199</td>\n",
       "      <td>166146</td>\n",
       "      <td>379327</td>\n",
       "      <td>2</td>\n",
       "      <td>35209</td>\n",
       "      <td>178740</td>\n",
       "      <td>1029446</td>\n",
       "      <td>354409</td>\n",
       "      <td>1790136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>36</td>\n",
       "      <td>627951</td>\n",
       "      <td>684178</td>\n",
       "      <td>1312129</td>\n",
       "      <td>64143</td>\n",
       "      <td>229794</td>\n",
       "      <td>2</td>\n",
       "      <td>16155</td>\n",
       "      <td>128839</td>\n",
       "      <td>573768</td>\n",
       "      <td>138644</td>\n",
       "      <td>594522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>35</td>\n",
       "      <td>1454619</td>\n",
       "      <td>1481050</td>\n",
       "      <td>2935669</td>\n",
       "      <td>187896</td>\n",
       "      <td>337631</td>\n",
       "      <td>2</td>\n",
       "      <td>62613</td>\n",
       "      <td>148790</td>\n",
       "      <td>208043</td>\n",
       "      <td>703722</td>\n",
       "      <td>2463916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>34</td>\n",
       "      <td>432157</td>\n",
       "      <td>453424</td>\n",
       "      <td>885581</td>\n",
       "      <td>24953</td>\n",
       "      <td>225866</td>\n",
       "      <td>2</td>\n",
       "      <td>10729</td>\n",
       "      <td>48311</td>\n",
       "      <td>231822</td>\n",
       "      <td>309992</td>\n",
       "      <td>505674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code           state  median_age  male_population  female_population  \\\n",
       "0         MT         Montana          35            87707              93587   \n",
       "1         NC  North Carolina          33          1466105            1594094   \n",
       "2         MD        Maryland          36           627951             684178   \n",
       "3         CO        Colorado          35          1454619            1481050   \n",
       "4         CT     Connecticut          34           432157             453424   \n",
       "\n",
       "   total_population  veterans_num  foreign_born_population  \\\n",
       "0            181294         13854                     5977   \n",
       "1           3060199        166146                   379327   \n",
       "2           1312129         64143                   229794   \n",
       "3           2935669        187896                   337631   \n",
       "4            885581         24953                   225866   \n",
       "\n",
       "   avg_household_size  american_indian_alaska_native   asian  \\\n",
       "0                   2                           9684    4165   \n",
       "1                   2                          35209  178740   \n",
       "2                   2                          16155  128839   \n",
       "3                   2                          62613  148790   \n",
       "4                   2                          10729   48311   \n",
       "\n",
       "   african_american  hispanic_latino    white  \n",
       "0              3349            10000   169026  \n",
       "1           1029446           354409  1790136  \n",
       "2            573768           138644   594522  \n",
       "3            208043           703722  2463916  \n",
       "4            231822           309992   505674  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group table by state\n",
    "df_cities= df_cities.groupBy(col(\"state_code\"),col(\"state\"))\\\n",
    "            .agg(avg(\"median_age\").cast(IntegerType()).alias(\"median_age\"),\\\n",
    "                 sum(\"male_population\").cast(IntegerType()).alias(\"male_population\"),\\\n",
    "                 sum(\"female_population\").cast(IntegerType()).alias(\"female_population\"),\\\n",
    "                 sum(\"total_population\").cast(IntegerType()).alias(\"total_population\"),\\\n",
    "                 sum(\"veterans_num\").cast(IntegerType()).alias(\"veterans_num\"),\\\n",
    "                 sum(\"foreign_born_population\").cast(IntegerType()).alias(\"foreign_born_population\"),\\\n",
    "                 avg(\"avg_household_size\").cast(IntegerType()).alias(\"avg_household_size\"),\\\n",
    "                 sum(\"american_indian_alaska_native\").cast(IntegerType()).alias(\"american_indian_alaska_native\"),\n",
    "                 sum(\"asian\").cast(IntegerType()).alias(\"asian\"),\\\n",
    "                 sum(\"african_american\").cast(IntegerType()).alias(\"african_american\"),\\\n",
    "                 sum(\"hispanic_latino\").cast(IntegerType()).alias(\"hispanic_latino\"),\\\n",
    "                 sum(\"white\").cast(IntegerType()).alias(\"white\"))\n",
    "df_cities.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: integer (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      " |-- veterans_num: integer (nullable = true)\n",
      " |-- foreign_born_population: integer (nullable = true)\n",
      " |-- avg_household_size: integer (nullable = true)\n",
      " |-- american_indian_alaska_native: integer (nullable = true)\n",
      " |-- asian: integer (nullable = true)\n",
      " |-- african_american: integer (nullable = true)\n",
      " |-- hispanic_latino: integer (nullable = true)\n",
      " |-- white: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cities.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tempratures data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>10.779000000000002</td>\n",
       "      <td>1.942</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>17.992</td>\n",
       "      <td>1.849</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>13.325</td>\n",
       "      <td>2.137</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.896</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>16.41</td>\n",
       "      <td>1.893</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Spain</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>8.73W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature AverageTemperatureUncertainty      City  \\\n",
       "0  1743-11-01  10.779000000000002                         1.942  A Coruña   \n",
       "1  1744-07-01              17.992                         1.849  A Coruña   \n",
       "2  1743-12-01                None                          None  A Coruña   \n",
       "3  1744-01-01                None                          None  A Coruña   \n",
       "4  1744-02-01                None                          None  A Coruña   \n",
       "5  1744-03-01                None                          None  A Coruña   \n",
       "6  1744-04-01              13.325                         2.137  A Coruña   \n",
       "7  1744-05-01                12.9                         1.896  A Coruña   \n",
       "8  1744-06-01               16.41                         1.893  A Coruña   \n",
       "\n",
       "  Country Latitude Longitude  \n",
       "0   Spain   42.59N     8.73W  \n",
       "1   Spain   42.59N     8.73W  \n",
       "2   Spain   42.59N     8.73W  \n",
       "3   Spain   42.59N     8.73W  \n",
       "4   Spain   42.59N     8.73W  \n",
       "5   Spain   42.59N     8.73W  \n",
       "6   Spain   42.59N     8.73W  \n",
       "7   Spain   42.59N     8.73W  \n",
       "8   Spain   42.59N     8.73W  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.sort(df_temperature.City).limit(9).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uzbekistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Country\n",
       "0         United States\n",
       "1               Ukraine\n",
       "2               Uruguay\n",
       "3                Uganda\n",
       "4  United Arab Emirates\n",
       "5            Uzbekistan\n",
       "6        United Kingdom"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.select('Country').where(col(\"Country\").like(\"U%\")).distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data with United States country only\n",
    "df_temperature = df_temperature.filter(df_temperature.Country == 'United States')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates \n",
    "df_temperature = df_temperature.dropDuplicates(['dt', 'City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with 100% missing values and rows which have missing values in important data field \"AverageTemperature\"\n",
    "\n",
    "df_temperature = df_temperature.dropna(how='all', subset=['AverageTemperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max date</th>\n",
       "      <th>min date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>1743-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max date    min date\n",
       "0  2013-09-01  1743-11-01"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data between which dates\n",
    "df_temperature.select(max(df_temperature.dt).alias(\"max date\"), min(df_temperature.dt).alias(\"min date\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt\n",
       "0  2013-09-01\n",
       "1  2013-05-01\n",
       "2  2013-02-01\n",
       "3  2013-07-01\n",
       "4  2013-03-01\n",
       "5  2013-06-01\n",
       "6  2013-04-01\n",
       "7  2013-08-01\n",
       "8  2013-01-01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.select(df_temperature.dt).where(df_temperature.dt >= '2013-01-01').distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop anything before 2013 to use for averages\n",
    "df_temperature = df_temperature.filter(df_temperature.dt >= '2013-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: integer (nullable = true)\n",
      " |-- average_temperature: double (nullable = true)\n",
      " |-- average_temperature_uncertainty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatypes, format column names \n",
    "df_temperature = df_temperature.withColumn(\"month\", month(df_temperature.dt))\\\n",
    "    .withColumn(\"date\",col(\"dt\").cast(DateType())).drop(\"dt\") \\\n",
    "    .withColumn(\"average_temperature\",col(\"AverageTemperature\").cast(FloatType())).drop(\"AverageTemperature\") \\\n",
    "    .withColumn(\"average_temperature_uncertainty\",col(\"AverageTemperatureUncertainty\").cast(FloatType())).drop(\"AverageTemperatureUncertainty\")\\\n",
    "    .withColumnRenamed(\"City\", \"city\") \\\n",
    "    .withColumnRenamed(\"Country\", \"country\") \\\n",
    "    .withColumnRenamed(\"Latitude\", \"latitude\") \\\n",
    "    .withColumnRenamed(\"Longitude\", \"longitude\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston</td>\n",
       "      <td>United States</td>\n",
       "      <td>29.74N</td>\n",
       "      <td>96.00W</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>112.02W</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>11.201000</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anaheim</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>117.77W</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>15.344000</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Newark</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>74.56W</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>9.723000</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>16.789000</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Norfolk</td>\n",
       "      <td>United States</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>75.58W</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>19.249001</td>\n",
       "      <td>0.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>United States</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>116.76W</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>26.841999</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tacoma</td>\n",
       "      <td>United States</td>\n",
       "      <td>47.42N</td>\n",
       "      <td>121.97W</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>17.033001</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thornton</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>104.05W</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>22.065001</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Memphis</td>\n",
       "      <td>United States</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>89.51W</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>25.007000</td>\n",
       "      <td>1.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city        country latitude longitude  month        date  \\\n",
       "0           Houston  United States   29.74N    96.00W      1  2013-01-01   \n",
       "1              Mesa  United States   32.95N   112.02W      2  2013-02-01   \n",
       "2           Anaheim  United States   32.95N   117.77W      3  2013-03-01   \n",
       "3            Newark  United States   40.99N    74.56W      4  2013-04-01   \n",
       "4         Cleveland  United States   40.99N    80.95W      5  2013-05-01   \n",
       "5           Norfolk  United States   36.17N    75.58W      5  2013-05-01   \n",
       "6  Rancho Cucamonga  United States   34.56N   116.76W      6  2013-06-01   \n",
       "7            Tacoma  United States   47.42N   121.97W      7  2013-07-01   \n",
       "8          Thornton  United States   39.38N   104.05W      7  2013-07-01   \n",
       "9           Memphis  United States   34.56N    89.51W      9  2013-09-01   \n",
       "\n",
       "   average_temperature  average_temperature_uncertainty  \n",
       "0            12.550000                            0.447  \n",
       "1            11.201000                            0.292  \n",
       "2            15.344000                            0.486  \n",
       "3             9.723000                            0.355  \n",
       "4            16.789000                            0.263  \n",
       "5            19.249001                            0.369  \n",
       "6            26.841999                            0.488  \n",
       "7            17.033001                            0.248  \n",
       "8            22.065001                            0.235  \n",
       "9            25.007000                            1.118  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.569964</td>\n",
       "      <td>0.379331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>23.262520</td>\n",
       "      <td>0.305762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.214806</td>\n",
       "      <td>0.330601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>18.670540</td>\n",
       "      <td>0.316173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>22.404085</td>\n",
       "      <td>1.064927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>13.813677</td>\n",
       "      <td>0.343258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>24.155560</td>\n",
       "      <td>0.384395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>24.947448</td>\n",
       "      <td>0.306347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6.118089</td>\n",
       "      <td>0.324500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  average_temperature  average_temperature_uncertainty\n",
       "0      1             5.569964                         0.379331\n",
       "1      6            23.262520                         0.305762\n",
       "2      3             9.214806                         0.330601\n",
       "3      5            18.670540                         0.316173\n",
       "4      9            22.404085                         1.064927\n",
       "5      4            13.813677                         0.343258\n",
       "6      8            24.155560                         0.384395\n",
       "7      7            24.947448                         0.306347\n",
       "8      2             6.118089                         0.324500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature = df_temperature.groupBy(col(\"month\"))\\\n",
    "                .agg(avg(\"average_temperature\").alias(\"average_temperature\"),\\\n",
    "                    avg(\"average_temperature_uncertainty\").alias(\"average_temperature_uncertainty\"))\n",
    "df_temperature.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "As previously mentioned, the chosen data model was the star schema, That model was the chosen one because it allows great performance, and it also allows users to write simple queries joining the fact and dimension tables in order to achieve the analytical dataset they need and perform BI solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact table: \n",
    "- 'immigrations' table: fk(cic_id, port, arrive_state, arrive_month, arrival_date, departure_date, allowed_date)\n",
    "\n",
    "#### Dimensions tables: \n",
    "- #1: 'immigrants' table: pk: cic_id, birth_year, age, gender, airline, flight_num, visa_type, visa_class, visa_issue_state, mode, citizen_country, resident_country\n",
    "\n",
    "- #2: 'demographics' table: pk: state_code, state, median_age, male_population, female_population, total_population, veterans_num, foreign_born_population, avg_household_size, american_indian_alaska_native, asian, african_american, hispanic_latino, white\n",
    "\n",
    "- #3: 'airports' table: pk: iata_code, name, type, state, elevation_ft, latitude, longitude\n",
    "\n",
    "- #4: 'temperatures' table: pk: month, average_temperature, average_temperature_uncertainty\n",
    "\n",
    "- #5: 'date' table: pk: date_key, date, day, month, year, weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "the steps necessary to pipeline the data into the chosen data model:\n",
    "\n",
    "- Extract Data for immigrants Table from immigration dataframe and Write data into parquet files\n",
    "- Extract Data for demographics Table from demographics dataframe and Write data into parquet files\n",
    "- Extract Data for airports Table from airports dataframe and Write data into parquet files\n",
    "- Extract Data for temperatures Table from temperatures dataframe and Write data into parquet files\n",
    "- Extract Data for Date Table from immigration dataframe and Write data into parquet files\n",
    "- Extract Data and immigrations Table from immigration dataframe and Write data into parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1: 'immigrants' Table\n",
    "#### Extract Data for immigrants Table\n",
    "- Select columns for cic_id, birth_year, age, gender, airline, flight_num, visa_type, visa_class, visa_issue_state, mode, citizen_country, resident_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigrants_table = df_immigration.select('cic_id', 'birth_year', 'age', 'gender', 'airline', 'flight_num', 'visa_type', 'visa_class',\\\n",
    "                                       'visa_issue_state', 'mode', 'citizen_country_name', 'resident_country_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_num</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>visa_class</th>\n",
       "      <th>visa_issue_state</th>\n",
       "      <th>mode</th>\n",
       "      <th>citizen_country_name</th>\n",
       "      <th>resident_country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018851</td>\n",
       "      <td>1986</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>CX</td>\n",
       "      <td>00840</td>\n",
       "      <td>WT</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Air</td>\n",
       "      <td>None</td>\n",
       "      <td>BURMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cic_id  birth_year  age gender airline flight_num visa_type visa_class  \\\n",
       "0  2018851        1986   30      M      CX      00840        WT   Pleasure   \n",
       "\n",
       "  visa_issue_state mode citizen_country_name resident_country_name  \n",
       "0          unknown  Air                 None                 BURMA  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrants_table.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write immigrates table to parquet files partitioned by visa_class\n",
    "immigrants_table.write.mode('overwrite').partitionBy('visa_class').parquet('immigrants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2: 'demographics' Table\n",
    "#### Extract Data for demographics Table\n",
    "- Select columns for state_code, state, median_age, male_population, female_population, total_population, veterans_num, foreign_born_population, avg_household_size, american_indian_alaska_native, asian, african_american, hispanic_latino, white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>veterans_num</th>\n",
       "      <th>foreign_born_population</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>american_indian_alaska_native</th>\n",
       "      <th>asian</th>\n",
       "      <th>african_american</th>\n",
       "      <th>hispanic_latino</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT</td>\n",
       "      <td>Montana</td>\n",
       "      <td>35</td>\n",
       "      <td>87707</td>\n",
       "      <td>93587</td>\n",
       "      <td>181294</td>\n",
       "      <td>13854</td>\n",
       "      <td>5977</td>\n",
       "      <td>2</td>\n",
       "      <td>9684</td>\n",
       "      <td>4165</td>\n",
       "      <td>3349</td>\n",
       "      <td>10000</td>\n",
       "      <td>169026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code    state  median_age  male_population  female_population  \\\n",
       "0         MT  Montana          35            87707              93587   \n",
       "\n",
       "   total_population  veterans_num  foreign_born_population  \\\n",
       "0            181294         13854                     5977   \n",
       "\n",
       "   avg_household_size  american_indian_alaska_native  asian  african_american  \\\n",
       "0                   2                           9684   4165              3349   \n",
       "\n",
       "   hispanic_latino   white  \n",
       "0            10000  169026  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_table = df_cities.select('state_code', 'state', 'median_age', 'male_population', 'female_population', \\\n",
    "                                      'total_population', 'veterans_num', 'foreign_born_population', 'avg_household_size',\\\n",
    "                                      'american_indian_alaska_native', 'asian', 'african_american', 'hispanic_latino', 'white')\n",
    "\n",
    "demographics_table.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write demographics table to parquet files partitioned by state_code\n",
    "demographics_table.write.mode('overwrite').partitionBy('state_code').parquet('demographics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #3: 'airports' Table\n",
    "#### Extract Data for airports Table\n",
    "- Select columns for iata_code, name, type, state, elevation_ft, latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata_code</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>state</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVP</td>\n",
       "      <td>Wilkes Barre Scranton International Airport</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>PA</td>\n",
       "      <td>962</td>\n",
       "      <td>-75.72339630130001</td>\n",
       "      <td>41.338500976599995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iata_code                                         name            type  \\\n",
       "0       AVP  Wilkes Barre Scranton International Airport  medium_airport   \n",
       "\n",
       "  state elevation_ft            latitude            longitude  \n",
       "0    PA          962  -75.72339630130001   41.338500976599995  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_table = df_airport.select('iata_code', 'name', 'type', 'state', 'elevation_ft', 'latitude', 'longitude')\n",
    "\n",
    "airports_table.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write airports table to parquet files partitioned by type\n",
    "airports_table.write.mode('overwrite').partitionBy('type').parquet('airports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4: 'temperatures' Table\n",
    "#### Extract Data for temperatures Table\n",
    "- Select columns for month, average_temperature, average_temperature_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.569964</td>\n",
       "      <td>0.379331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  average_temperature  average_temperature_uncertainty\n",
       "0      1             5.569964                         0.379331"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures_table = df_temperature.select('month', 'average_temperature', 'average_temperature_uncertainty')\n",
    "\n",
    "temperatures_table.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write temperatures table to parquet files \n",
    "temperatures_table.write.mode('overwrite').parquet('temperatures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5: `Date` Table\n",
    "#### Extract Data for Date Table\n",
    "- Extract the date, day, month, year, and weekday from the dates column \n",
    "- Specify labels for these columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arrival_date\n",
       "0   2017-08-11\n",
       "1   2017-09-11\n",
       "2   2016-04-25\n",
       "3   2018-03-17\n",
       "4   2017-01-06"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df_immigration.select(\"arrival_date\").union(df_immigration.select(\"departure_date\"))\\\n",
    "                                    .union(df_immigration.select(\"allowed_date\")).distinct()\n",
    "d.limit(5).toPandas()                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- date_key: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  day  month  year  weekday\n",
       "0  2017-08-11   11      8  2017        6\n",
       "1  2017-09-11   11      9  2017        2\n",
       "2  2016-04-25   25      4  2016        2\n",
       "3  2018-03-17   17      3  2018        7\n",
       "4  2017-01-06    6      1  2017        6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d.withColumn(\"date_key\", date_format(d.arrival_date,\"yyyyMMdd\"))\\\n",
    "    .withColumn(\"day\", dayofmonth(d.arrival_date))\\\n",
    "    .withColumn(\"month\", month(d.arrival_date))\\\n",
    "    .withColumn(\"year\", year(d.arrival_date))\\\n",
    "    .withColumn(\"weekday\", dayofweek(d.arrival_date))\\\n",
    "    .withColumnRenamed(\"arrival_date\", \"date\")\n",
    "\n",
    "d.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>date_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>20170811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>20170911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>20160425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>20180317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>20170106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  day  month  year  weekday  date_key\n",
       "0  2017-08-11   11      8  2017        6  20170811\n",
       "1  2017-09-11   11      9  2017        2  20170911\n",
       "2  2016-04-25   25      4  2016        2  20160425\n",
       "3  2018-03-17   17      3  2018        7  20180317\n",
       "4  2017-01-06    6      1  2017        6  20170106"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dates table to parquet files partitioned by year and month\n",
    "d.write.mode('overwrite').partitionBy('year', 'month').parquet('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #6: `immigrations` Table\n",
    "#### Extract Data and immigrations Table\n",
    "\n",
    "- Select the port, arrive_state, arrival_date_key, departure_date_key, allowed_date_key, cic_id, arrive_month and set to `immigrations_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>arrive_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>allowed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018851</td>\n",
       "      <td>NYC</td>\n",
       "      <td>CT</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1835040</td>\n",
       "      <td>HHW</td>\n",
       "      <td>HI</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2016-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1835041</td>\n",
       "      <td>HHW</td>\n",
       "      <td>HI</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2016-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2352309</td>\n",
       "      <td>FTL</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>2016-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680670</td>\n",
       "      <td>NYC</td>\n",
       "      <td>FL</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016-07-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cic_id port arrive_state  arrive_month arrival_date departure_date  \\\n",
       "0  2018851  NYC           CT             4   2016-04-11     2016-04-23   \n",
       "1  1835040  HHW           HI             4   2016-04-10     2016-04-19   \n",
       "2  1835041  HHW           HI             4   2016-04-10     2016-04-19   \n",
       "3  2352309  FTL           IL             4   2016-04-13     2016-04-17   \n",
       "4   680670  NYC           FL             4   2016-04-04     2016-04-11   \n",
       "\n",
       "  allowed_date  \n",
       "0   2016-07-09  \n",
       "1   2016-07-08  \n",
       "2   2016-07-08  \n",
       "3   2016-07-11  \n",
       "4   2016-07-02  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrations_table = df_immigration.select('cic_id', 'port', 'arrive_state', 'arrive_month', 'arrival_date', 'departure_date',\\\n",
    "                                           'allowed_date')\n",
    "immigrations_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>arrive_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>allowed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018851</td>\n",
       "      <td>NYC</td>\n",
       "      <td>CT</td>\n",
       "      <td>4</td>\n",
       "      <td>20160411</td>\n",
       "      <td>20160423</td>\n",
       "      <td>20160709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1835040</td>\n",
       "      <td>HHW</td>\n",
       "      <td>HI</td>\n",
       "      <td>4</td>\n",
       "      <td>20160410</td>\n",
       "      <td>20160419</td>\n",
       "      <td>20160708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1835041</td>\n",
       "      <td>HHW</td>\n",
       "      <td>HI</td>\n",
       "      <td>4</td>\n",
       "      <td>20160410</td>\n",
       "      <td>20160419</td>\n",
       "      <td>20160708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2352309</td>\n",
       "      <td>FTL</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>20160413</td>\n",
       "      <td>20160417</td>\n",
       "      <td>20160711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680670</td>\n",
       "      <td>NYC</td>\n",
       "      <td>FL</td>\n",
       "      <td>4</td>\n",
       "      <td>20160404</td>\n",
       "      <td>20160411</td>\n",
       "      <td>20160702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cic_id port arrive_state  arrive_month arrival_date departure_date  \\\n",
       "0  2018851  NYC           CT             4     20160411       20160423   \n",
       "1  1835040  HHW           HI             4     20160410       20160419   \n",
       "2  1835041  HHW           HI             4     20160410       20160419   \n",
       "3  2352309  FTL           IL             4     20160413       20160417   \n",
       "4   680670  NYC           FL             4     20160404       20160411   \n",
       "\n",
       "  allowed_date  \n",
       "0     20160709  \n",
       "1     20160708  \n",
       "2     20160708  \n",
       "3     20160711  \n",
       "4     20160702  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrations_table = immigrations_table.withColumn(\"arrival_date\", date_format(immigrations_table.arrival_date,\"yyyyMMdd\"))\\\n",
    "                                        .withColumn(\"departure_date\", date_format(immigrations_table.departure_date,\"yyyyMMdd\"))\\\n",
    "                                        .withColumn(\"allowed_date\", date_format(immigrations_table.allowed_date,\"yyyyMMdd\"))\n",
    "immigrations_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write immigrations table to parquet files partitioned by arrive_state\n",
    "immigrations_table.write.mode('overwrite').partitionBy('arrive_state').parquet('immigrations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "the data quality checks perform to ensure the pipeline ran as expected:\n",
    "- Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "- Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final tables \n",
    "fact_immigrations = spark.read.parquet(\"immigrations\")\n",
    "dim_immigrants = spark.read.parquet(\"immigrants\")\n",
    "dim_demographics = spark.read.parquet(\"demographics\")\n",
    "dim_airports = spark.read.parquet(\"airports\")\n",
    "dim_temperatures = spark.read.parquet(\"temperatures\")\n",
    "dim_date = spark.read.parquet(\"date\")\n",
    "tablelist = [fact_immigrations,dim_immigrants,dim_demographics,dim_airports,dim_temperatures,dim_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rows in tables and column types\n",
    "def check_rows(tablelist):\n",
    "    for table in tablelist:\n",
    "        if table.count() > 0:\n",
    "            print(\"Quality check passed for {} table is not empty\".format(table))\n",
    "        else:\n",
    "            print(\"Quality check failed. No records in {} table\".format(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check passed for DataFrame[cic_id: int, port: string, arrive_month: int, arrival_date: string, departure_date: string, allowed_date: string, arrive_state: string] table is not empty\n",
      "Quality check passed for DataFrame[cic_id: int, birth_year: int, age: int, gender: string, airline: string, flight_num: string, visa_type: string, visa_issue_state: string, mode: string, citizen_country_name: string, resident_country_name: string, visa_class: string] table is not empty\n",
      "Quality check passed for DataFrame[state: string, median_age: int, male_population: int, female_population: int, total_population: int, veterans_num: int, foreign_born_population: int, avg_household_size: int, american_indian_alaska_native: int, asian: int, african_american: int, hispanic_latino: int, white: int, state_code: string] table is not empty\n",
      "Quality check passed for DataFrame[iata_code: string, name: string, state: string, elevation_ft: string, latitude: string, longitude: string, type: string] table is not empty\n",
      "Quality check passed for DataFrame[month: int, average_temperature: double, average_temperature_uncertainty: double] table is not empty\n",
      "Quality check passed for DataFrame[date: date, day: int, weekday: int, date_key: string, year: int, month: int] table is not empty\n"
     ]
    }
   ],
   "source": [
    "check_rows(tablelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_keys(fact,dim1,dim2,dim3,dim4,dim5):\n",
    "    if fact.groupBy('cic_id', 'port', 'arrive_state', 'arrive_month', 'arrival_date', 'departure_date','allowed_date').count().filter(\"count > 1\").count() == 0:\n",
    "        print(\"Immigrations Fact table's keys are unique\")\n",
    "    else:\n",
    "        print(\"Immigrations Fact table's keys are not unique\")\n",
    "    if dim1.groupBy(\"cic_id\").count().filter(\"count > 1\").count() == 0:\n",
    "        print(\"Immigrants Dimention table's keys are unique\")\n",
    "    else:\n",
    "        print(\"Immigrants Dimention table's keys are not unique\")\n",
    "    if dim2.groupBy(\"state_code\").count().filter(\"count > 1\").count() == 0:\n",
    "        print(\"Demographics Dimention table's keys are unique\")\n",
    "    else:\n",
    "        print(\"Demographics Dimention table's keys are not unique\")\n",
    "    if dim3.groupBy(\"iata_code\").count().filter(\"count > 1\").count() == 0:\n",
    "        print(\"Airports Dimention table's keys are unique\")\n",
    "    else:\n",
    "        print(\"Airports Dimention table's keys are not unique\")\n",
    "    if dim4.groupBy(\"month\").count().filter(\"count > 1\").count() == 0:\n",
    "        print(\"Temperatures Dimention table's keys are unique\")\n",
    "    else:\n",
    "        print(\"Temperatures Dimention table's keys are not unique\")\n",
    "    if dim5.groupBy(\"date_key\").count().filter(\"count > 1\").count() == 0:\n",
    "        print(\"Date Dimention table's keys are unique\")\n",
    "    else:\n",
    "        print(\"Date Dimention table's keys are not unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immigrations Fact table's keys are unique\n",
      "Immigrants Dimention table's keys are unique\n",
      "Demographics Dimention table's keys are unique\n",
      "Airports Dimention table's keys are unique\n",
      "Temperatures Dimention table's keys are unique\n",
      "Date Dimention table's keys are unique\n"
     ]
    }
   ],
   "source": [
    "check_unique_keys(*tablelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Data dictionary for data model. For each field, provide a brief description of what the data is and where it came from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions tables: \n",
    "- #1: 'immigrants' table: \n",
    "        - cic_id: primary key, INT, (immigrant id)\n",
    "        - birth_year: INT, (4 digit year of immigrant birth)\n",
    "        - age: INT, (Age of immigrant in Years)\n",
    "        - gender: String, (immigrant sex)\n",
    "        - airline: String,(Airline used to arrive in U.S.) \n",
    "        - flight_num: String, (Flight number of Airline used to arrive in U.S.)\n",
    "        - visa_type: String, (Class of admission legally admitting the immigrant to temporarily stay in U.S.)\n",
    "        - visa_class: String, (Visa class collapsed into three categories Business, Pleasure, Student)\n",
    "        - visa_issue_state: String, (Department of State where Visa was issued)\n",
    "        - mode: String, (Mode of transportation collapsed into three categories 'Air','Sea','Land')\n",
    "        - citizen_country: String, (Country of citizenship)\n",
    "        - resident_country: String, (Country of residence)\n",
    "\n",
    "- #2: 'demographics' table: \n",
    "        - state_code: primary key, String, (code of state)\n",
    "        - state: String, (name of state)\n",
    "        - median_age:  INT, (Average age of residents)\n",
    "        - male_population: INT, (Number of male residents)\n",
    "        - female_population: INT, (Number of female residents)\n",
    "        - total_population: INT, (Number of total residents)\n",
    "        - veterans_num: INT, (Number of residents that are veterans)\n",
    "        - foreign_born_population: INT, (Number of residents not born in country)\n",
    "        - avg_household_size: INT, (Average size of residents in single house)\n",
    "        - american_indian_alaska_native: INT, (Number of residents thier race is american indian alaska native)\n",
    "        - asian: INT, (Number of residents thier race is asian)\n",
    "        - african_american: INT, (Number of residents thier race is african american)\n",
    "        - hispanic_latino: INT, (Number of residents thier race is hispanic latino) \n",
    "        - white: INT, (Number of residents thier race is white) \n",
    "\n",
    "- #3: 'airports' table: \n",
    "        - iata_code: Primary Key, String, (International Air Transport Association airport code)\n",
    "        - name: String, (Airport name)\n",
    "        - type: String, (Type of airport by size) \n",
    "        - state: String, (state of airport location)\n",
    "        - elevation_ft: String, (Elevation of airport in feet)\n",
    "        - latitude: String, (Latitude of airport)\n",
    "        - longitude: String, (Longitude of airport)\n",
    "\n",
    "- #4: 'temperatures' table: \n",
    "        - month: Primary Key, INT, (the month of average temperature)\n",
    "        - average_temperature: DOUBLE, (average temperature in U.S. by month) \n",
    "        - average_temperature_uncertainty: DOUBLE, (Uncertainty of Avg Temp in U.S. by month)\n",
    "\n",
    "- #5: 'date' table: \n",
    "        - date_key: Primary Key, String, (key of the date)\n",
    "        - date: DATE, (date)\n",
    "        - day: INT, (day of the date)\n",
    "        - month: INT, (month of the date)\n",
    "        - year: INT, (year of the date)\n",
    "        - weekday: INT, (the day of the week)\n",
    "        \n",
    "#### Fact table: \n",
    "- 'immigrations' table: \n",
    "        - cic_id: Foreign Key, INT, (cic_id 'immigrants' table referenced )\n",
    "        - port: Foreign Key, String, (iata_code 'airports' table referenced)\n",
    "        - arrive_state: Foreign Key, String, (state_code 'demographics' table referenced)\n",
    "        - arrive_month: Foreign Key, INT, (month 'temperature' table referenced)\n",
    "        - arrival_date: Foreign Key, String, (date_key 'date' table referenced)\n",
    "        - departure_date: Foreign Key, String, (date_key 'date' table referenced)\n",
    "        - allowed_date: Foreign Key, String, (date_key 'date' table referenced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "    The project uses Apache Spark engine. Spark is an simple and fast and also scalable analytics engine for large scale data processing. It has an ability to process and analyse massive ammounts of data using PySpark interface. Can handle different data formats (e.g. SAS, Parquet, CSV), and can be integrated with cloud storage solutions like S3 or Redshift.\n",
    "\n",
    "    Python is used since it is powerful for dev works in Jupyter notebook and ETL building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "    - Immigration data: data are provided on a monthly basis, and hence should be updated monthly\n",
    "    - Temperature data: data runs until 2013, needs to be updated as the fact immigration is for 2016, hence data should be updated yearly\n",
    "    - Demographics data: updates are provided on a yearly basis to the public and hence, a yearly update is sufficient\n",
    "    - Airports data: can be assumed to be constant\n",
    "    - Date data: updated periodically only once per month\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A description of how would approach the problem differently under the following scenarios:\n",
    "\n",
    " * The data was increased by 100x.\n",
    " \n",
    "         Currently the Spark instance installed locally is used. However, local/stand-alone Spark may not offer the optimum performance for larger datasets. Pyspark locally begins to lack computational power. \n",
    "         In this case, it would be interesting to work with cloud technology such as AWS. Creating a cluster in AWS should be considered, it would Upload the data to S3 and then use Redshift to perform the ETL and generate the data model.\n",
    "         \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "         \n",
    "        In this case, I would move on a AWS Cloud platform and connect with proper BI tools (Tableau for example) and automate the entire data flow using Airflow. If a time is scheduled so that the dashboard to be updated, then this would be a perfect use case to utilize Apache Airflow to carry out this assignemnt. Within Apache Airflow, can set schedules so that the data can be refreshed on a daily basis by 7am every day. Accordingly, the dashboard that's built based on the data will also be updated.\n",
    "        Airflow is a great solution to schedule and automate a data pipeline it can be easily supported by changing the \"schedule_interval\" value in the dags/airflow_pipeline.py code for Apache Airflow to schedule it for daily run.\n",
    "        \n",
    " * The database needed to be accessed by 100+ people.\n",
    "     \n",
    "         Currently no database is created behind this solution as this is designed for analytical purposes for a small scale of users. \n",
    "         In this case, Data can be migrated to Amazon Redshift cloud solution, Where it can help manage the user's workload, computational resources, ensure that every user has defined access depending on their role, allow auto-scaling capabilities to handle the load of increased access by users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
